{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating video frames count of all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "#change the path accordingly\n",
    "video_files =  os.listdir('fake_videos')\n",
    "\n",
    "print(len(video_files))\n",
    "frame_count = []\n",
    "sum=0\n",
    "count=0\n",
    "for video_file in video_files:\n",
    "    f='fake_videos'+\"/\"+video_file\n",
    "    cap = cv2.VideoCapture(f)\n",
    "    frames_len=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count.append(frames_len)\n",
    "    sum=sum+frames_len\n",
    "    #if frames_len <170:\n",
    "       # count+=1\n",
    "print(\"frames\" , frame_count)\n",
    "print (sum)\n",
    "#print (count)\n",
    "\n",
    "#print(\"Total number of videos: \" , len(frame_count))\n",
    "#print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving frames of videos in .jpg format of fake and real videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "classifier = cv2.CascadeClassifier('hcd.xml') \n",
    "# Opens the Video file\n",
    "directory=os.listdir('fake_videos')\n",
    "for video_file in directory:\n",
    "    f='fake_videos'+\"/\"+video_file\n",
    "    cap= cv2.VideoCapture(f)\n",
    "    i=0\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "           \n",
    "        if i%50==0:\n",
    "            faces = classifier.detectMultiScale(frame,minNeighbors=30) \n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = frame[y:y+h, x:x+w]\n",
    "                #cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cv2.imwrite(video_file +str(i)+'.jpg',roi)\n",
    "        #cv2.imshow('live',frame)\n",
    "        cv2.waitKey(1)\n",
    "        i+=1    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, # You can uncomment these parameters to make you generator rotate & flip the images to put the train model in stricter conditions.\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    #validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = idg.flow_from_directory(\"data2/train_data\",\n",
    "                                                   target_size=(128,128),                                                   \n",
    "                                                   subset='training',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = idg.flow_from_directory(\"data2/validation\",\n",
    "                                                   target_size=(128,128),                                                   \n",
    "                                                   #subset='validation',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   shuffle=True,\n",
    "                                                 \n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing some pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "input_shape = (128,128, 3)\n",
    "googleNet_model =ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "googleNet_model.trainable = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(googleNet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              # min_delta=0,\n",
    "                              # patience=3,\n",
    "                              # verbose=0,\n",
    "                              # restore_best_weights = True)\n",
    "\n",
    "checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "   'final_InceptionV3.h5',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE =32\n",
    "history = model.fit(train_gen, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = val_gen, verbose = 1,callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('deepfake_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model=load_model(\"deepfake_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "path='test'\n",
    "for vid in os.listdir(path):\n",
    "    if vid!='test1':\n",
    "        f=path+\"/\"+vid \n",
    "        data.append(vid)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label='fake'\n",
    "\n",
    "df['label']=Label\n",
    "df['real']=0\n",
    "df['fake']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "t = f.suptitle('Pre-trained Performance ', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,EPOCHS+1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch #')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch #')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for test videos predicting for every frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "path='test'\n",
    "i=0\n",
    "for vid in os.listdir(path):\n",
    "    if vid!='test1':\n",
    "        f=path+\"/\"+vid \n",
    "        cap = cv2.VideoCapture(f)\n",
    "\n",
    "        classifier = cv2.CascadeClassifier('hcd.xml')\n",
    "        real=0\n",
    "        fake=0\n",
    "        j=0\n",
    "\n",
    "        frame_count = []\n",
    "        frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "        #print(cap)   \n",
    "         #print(cap)   \n",
    "        while (cap.isOpened()):\n",
    "            (ret, im) = cap.read()\n",
    "            if ret == True:\n",
    "                if j%8==0:\n",
    "                    face = classifier.detectMultiScale(im,minNeighbors=20)\n",
    "                    for (x, y, w, h) in face:\n",
    "                        roi = im[y:y+h, x:x+w]\n",
    "                        resized=cv2.resize(roi,(128,128))\n",
    "                        resized_arr = image.img_to_array(resized)\n",
    "                        resized_arr=resized_arr/255\n",
    "                        resized_arr = np.expand_dims(resized_arr, axis = 0)\n",
    "                        result = model.predict(resized_arr)\n",
    "                        #print(result)\n",
    "                        predicted_class_indices=np.argmax(result,axis=1)\n",
    "                        #print(predicted_class_indices)\n",
    "                        if predicted_class_indices==1:\n",
    "                            real+=1\n",
    "                        else:\n",
    "                            fake+=1\n",
    "                        cv2.waitKey(1)\n",
    "                j+=1\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        #real_per=real/frame_count[0]\n",
    "        #fake_per=fake/frame_count[0]\n",
    "        #new_real=0.7*real\n",
    "        if fake>real:\n",
    "            print(i,vid,'fake',real,fake )\n",
    "            df['label'][i]='fake'\n",
    "            #df['fake'][i]=fake\n",
    "            #df['real'][i]=real\n",
    "        else:\n",
    "            print(i,vid,'real',real,fake )\n",
    "\n",
    "           # print(fake)\n",
    "           # print(frame_count)\n",
    "            df['label'][i]='real'\n",
    "            #df['real'][i]=real\n",
    "            #df['fake'][i]=fake\n",
    "        i+=1    \n",
    "    \n",
    "df['label'].replace({'fake':0, 'real':1}, inplace=True)    \n",
    "df.to_csv('deepfake_submission.csv',index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
